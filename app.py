import streamlit as st
import fitz  # PyMuPDF
import edge_tts
import asyncio
import io
import numpy as np
import easyocr
from langdetect import detect
from PIL import Image

st.set_page_config(page_title="Audiobook Pro", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ ××¢×‘×“ PDF ××ª×§×“×: ×¢××•×“×•×ª ×•×¡×¨×™×§×•×ª")

# ×”×’×“×¨×ª ×× ×•×¢ ×”-OCR (× ×˜×¢×Ÿ ×¤×¢× ××—×ª ×›×“×™ ×œ×—×¡×•×š ×–××Ÿ)
@st.cache_resource
def load_ocr():
    return easyocr.Reader(['he', 'en'])

reader = load_ocr()

# ×¤×•× ×§×¦×™×” ×œ×”×¤×§×ª ×§×•×œ
async def generate_audio(text, voice_name, speed):
    communicate = edge_tts.Communicate(text, voice_name, rate=speed)
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return audio_data

# ×¤×•× ×§×¦×™×” ×œ××™×•×Ÿ ×˜×§×¡×˜ ×œ×¤×™ ×¢××•×“×•×ª (×ª×¦×•×’×ª ×¢×™×ª×•×Ÿ)
def get_layout_aware_text(page):
    blocks = page.get_text("blocks")
    # ××™×•×Ÿ ×œ×¤×™ ×¢××•×“×” (×©×××œ ×œ×™××™×Ÿ ×‘×’×œ×œ ×¢×‘×¨×™×ª/×× ×’×œ×™×ª) ×•××– ×œ×¤×™ ×’×•×‘×”
    # ×‘-PDF ×¢×‘×¨×™, × ×¨×¦×” ×‘×“"×› ×©×”×¢××•×“×” ×”×™×× ×™×ª ×ª×§×¨× ×§×•×“×
    blocks.sort(key=lambda b: (b[0] < (page.rect.width / 2), b[1]))
    return " ".join([b[4].replace('\n', ' ') for b in blocks if b[4].strip()])

uploaded_file = st.file_uploader("×”×¢×œ×” ×§×•×‘×¥ PDF (×“×™×’×™×˜×œ×™ ××• ×¡×¨×•×§)", type="pdf")

VOICE_MAP = {
    "he": {"Female": "he-IL-HilaNeural", "Male": "he-IL-AvriNeural"},
    "en": {"Female": "en-US-EmmaNeural", "Male": "en-US-GuyNeural"}
}

if uploaded_file:
    with st.spinner("××¢×‘×“ ××ª ×”×§×•×‘×¥... ×–×” ×¢×©×•×™ ×œ×§×—×ª ×–××Ÿ ×‘×’×œ×œ ×”-OCR"):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        
        for page in doc:
            # 1. × ×™×¡×™×•×Ÿ ×œ×—×œ×¥ ×˜×§×¡×˜ ×“×™×’×™×˜×œ×™ ×¢× ×”×‘× ×” ×©×œ ×¢××•×“×•×ª
            page_text = get_layout_aware_text(page)
            
            # 2. ×× ×”×¢××•×“ ×¨×™×§ (×¡×¨×™×§×”), × ×¤×¢×™×œ OCR
            if len(page_text.strip()) < 10:
                pix = page.get_pixmap()
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                results = reader.readtext(np.array(img), paragraph=True)
                # ××™×•×Ÿ ×ª×•×¦××•×ª ×”-OCR ×œ×¤×™ ×¢××•×“×•×ª
                results.sort(key=lambda r: (r[0][0][0] < (pix.width / 2), r[0][0][1]))
                page_text = " ".join([r[1] for r in results])
            
            full_text += page_text + " "

        if full_text.strip():
            try:
                lang = detect(full_text[:500])
                st.write(f"**×©×¤×” ×©×–×•×”×ª×”:** {lang.upper()}")
                
                speed_pct = st.sidebar.slider("××”×™×¨×•×ª ×“×™×‘×•×¨ (%)", -50, 50, 0, 5)
                gender = st.radio("×‘×—×¨ ×§×•×œ:", ["Female", "Male"])
                
                supported_lang = "he" if lang == "he" else "en"
                selected_voice = VOICE_MAP[supported_lang][gender]

                if st.button("×¦×•×¨ ×§×•×‘×¥ ×©××¢"):
                    with st.spinner("××™×™×¦×¨ ××•×“×™×•..."):
                        audio_bytes = asyncio.run(generate_audio(full_text, selected_voice, f"{speed_pct:+d}%"))
                        st.audio(audio_bytes)
                        st.download_button("×”×•×¨×“ MP3", audio_bytes, "audiobook.mp3")
            except Exception as e:
                st.error(f"×©×’×™××”: {e}")
