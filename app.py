import streamlit as st
import fitz  # PyMuPDF
import edge_tts
import asyncio
import io
import numpy as np
import easyocr
from langdetect import detect
from PIL import Image

st.set_page_config(page_title="Audiobook Pro", page_icon="ðŸŽ™ï¸")
st.title("ðŸŽ™ï¸ ×ž×¢×‘×“ PDF ×ž×ª×§×“×: ×¢×ž×•×“×•×ª ×•×¡×¨×™×§×•×ª")

# ×”×’×“×¨×ª ×ž× ×•×¢ ×”-OCR (× ×˜×¢×Ÿ ×¤×¢× ××—×ª ×›×“×™ ×œ×—×¡×•×š ×–×ž×Ÿ)
@st.cache_resource
def load_ocr():
 # ×©×™× ×™× ×• ×ž-'he' ×œ-'iw' ×›×“×™ ×œ×¤×ª×•×¨ ××ª ×”×©×’×™××”
    return easyocr.Reader(['iw', 'en'])

reader = load_ocr()

# ×¤×•× ×§×¦×™×” ×œ×”×¤×§×ª ×§×•×œ
async def generate_audio(text, voice_name, speed):
    communicate = edge_tts.Communicate(text, voice_name, rate=speed)
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return audio_data

# ×¤×•× ×§×¦×™×” ×œ×ž×™×•×Ÿ ×˜×§×¡×˜ ×œ×¤×™ ×¢×ž×•×“×•×ª (×ª×¦×•×’×ª ×¢×™×ª×•×Ÿ)
def get_layout_aware_text(page):
    blocks = page.get_text("blocks")
    # ×ž×—×œ×§×™× ××ª ×”×“×£ ×‘××ž×¦×¢
    mid_point = page.rect.width / 2
    
    # ×ž×—×œ×§×™× ××ª ×”×‘×œ×•×§×™× ×œ×™×ž×™×Ÿ ×•×©×ž××œ
    right_column = [b for b in blocks if b[0] > mid_point]
    left_column = [b for b in blocks if b[0] <= mid_point]
    
    # ×‘×¢×‘×¨×™×ª: ×§×•×“× ×§×•×¨××™× ××ª ×¦×“ ×™×ž×™×Ÿ ×ž×œ×ž×¢×œ×” ×œ×ž×˜×”, ×•××– ××ª ×¦×“ ×©×ž××œ
    right_column.sort(key=lambda b: b[1])
    left_column.sort(key=lambda b: b[1])
    
    combined_blocks = right_column + left_column
    return " ".join([b[4].replace('\n', ' ') for b in combined_blocks if b[4].strip()])
uploaded_file = st.file_uploader("×”×¢×œ×” ×§×•×‘×¥ PDF (×“×™×’×™×˜×œ×™ ××• ×¡×¨×•×§)", type="pdf")

VOICE_MAP = {
    "he": {"Female": "he-IL-HilaNeural", "Male": "he-IL-AvriNeural"},
    "en": {"Female": "en-US-EmmaNeural", "Male": "en-US-GuyNeural"}
}

if uploaded_file:
    with st.spinner("×ž×¢×‘×“ ××ª ×”×§×•×‘×¥... ×–×” ×¢×©×•×™ ×œ×§×—×ª ×–×ž×Ÿ ×‘×’×œ×œ ×”-OCR"):
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        full_text = ""
        
        for page in doc:
            # 1. × ×™×¡×™×•×Ÿ ×œ×—×œ×¥ ×˜×§×¡×˜ ×“×™×’×™×˜×œ×™ ×¢× ×”×‘× ×” ×©×œ ×¢×ž×•×“×•×ª
            page_text = get_layout_aware_text(page)
            
            # 2. ×× ×”×¢×ž×•×“ ×¨×™×§ (×¡×¨×™×§×”), × ×¤×¢×™×œ OCR
            if len(page_text.strip()) < 10:
                pix = page.get_pixmap()
                img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                results = reader.readtext(np.array(img), paragraph=True)
                # ×ž×™×•×Ÿ ×ª×•×¦××•×ª ×”-OCR ×œ×¤×™ ×¢×ž×•×“×•×ª
                results.sort(key=lambda r: (r[0][0][0] < (pix.width / 2), r[0][0][1]))
                page_text = " ".join([r[1] for r in results])
            
            full_text += page_text + " "

        if full_text.strip():
            try:
                lang = detect(full_text[:500])
                st.write(f"**×©×¤×” ×©×–×•×”×ª×”:** {lang.upper()}")
                
                speed_pct = st.sidebar.slider("×ž×”×™×¨×•×ª ×“×™×‘×•×¨ (%)", -50, 50, 0, 5)
                gender = st.radio("×‘×—×¨ ×§×•×œ:", ["Female", "Male"])
                
                supported_lang = "he" if lang == "he" else "en"
                selected_voice = VOICE_MAP[supported_lang][gender]

                if st.button("×¦×•×¨ ×§×•×‘×¥ ×©×ž×¢"):
                    with st.spinner("×ž×™×™×¦×¨ ××•×“×™×•..."):
                        audio_bytes = asyncio.run(generate_audio(full_text, selected_voice, f"{speed_pct:+d}%"))
                        st.audio(audio_bytes)
                        st.download_button("×”×•×¨×“ MP3", audio_bytes, "audiobook.mp3")
            except Exception as e:
                st.error(f"×©×’×™××”: {e}")

